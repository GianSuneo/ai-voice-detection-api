from fastapi import FastAPI, HTTPException, Header
from pydantic import BaseModel
from typing import Optional
import joblib
import os
import base64
import numpy as np
import librosa
import io

# ---------------- APP INIT ----------------
app = FastAPI(title="AI-Generated Voice Detection API")

# ---------------- CONFIG ----------------
API_KEY = "my-secret-api-key"

# ---------------- MODEL LOADING ----------------
MODEL_PATH = os.path.join(os.path.dirname(__file__), "model.pkl")

try:
    model = joblib.load(MODEL_PATH)
    print("✅ Model loaded successfully")
except Exception as e:
    model = None
    print("❌ Model loading failed:", e)

# ---------------- INPUT SCHEMA ----------------
class VoiceInput(BaseModel):
    audio_base64: str
    language: str  # English, Hindi, Malayalam, Tamil, Telugu

# ---------------- HEALTH CHECK ----------------
@app.get("/")
def home():
    return {"message": "AI Voice Detection API is running"}

# ---------------- FEATURE EXTRACTION ----------------
def extract_features_from_base64(audio_base64: str):
    audio_bytes = base64.b64decode(audio_base64)
    audio_buffer = io.BytesIO(audio_bytes)

    y, sr = librosa.load(audio_buffer, sr=None)

    pitch = np.mean(librosa.yin(y, fmin=50, fmax=300))
    mfcc_mean = np.mean(librosa.feature.mfcc(y=y, sr=sr))
    spectral_flatness = np.mean(librosa.feature.spectral_flatness(y=y))
    zcr = np.mean(librosa.feature.zero_crossing_rate(y))
    rms = np.mean(librosa.feature.rms(y=y))
    centroid = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))
    bandwidth = np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr))

    return [[
        float(pitch),
        float(mfcc_mean),
        float(spectral_flatness),
        float(zcr),
        float(rms),
        float(centroid),
        float(bandwidth)
    ]]

# ---------------- MAIN ENDPOINT ----------------
@app.post("/detect-voice")
def detect_voice(
    data: VoiceInput,
    x_api_key: Optional[str] = Header(None)
):
    if x_api_key != API_KEY:
        raise HTTPException(status_code=401, detail="Invalid or missing API key")

    if not data.audio_base64:
        raise HTTPException(status_code=400, detail="Empty audio input")

    if data.language not in ["English", "Hindi", "Malayalam", "Tamil", "Telugu"]:
        raise HTTPException(status_code=400, detail="Unsupported language")

    if model is None:
        raise HTTPException(status_code=500, detail="Model not loaded")

    try:
        features = extract_features_from_base64(data.audio_base64)

        prediction = model.predict(features)[0]
        probabilities = model.predict_proba(features)[0]
        confidence = float(max(probabilities))

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Inference failed: {str(e)}")

    return {
        "classification": "AI-generated" if prediction == 1 else "Human",
        "confidence_score": round(confidence, 2),
        "explanation": [
            "MP3 audio decoded from base64",
            "Audio features extracted using DSP",
            "Prediction generated by trained ML model"
        ]
    }
















